{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nimport pickle\nfrom keras.models import model_from_json\nfrom keras.models import load_model\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n  #      print(os.path.join(dirname, filename))\n#/kaggle/input/image-classification-iecsexmrm/Train/Helianthus/Helianthus (362).jpg\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_list=[]\nclass_list=[]\nIMG_SIZE = 50\n\nDATADIR = 'Train'\n\nCATEGORIES = ['Bellis perennis','Helianthus','Rosa','Taraxacum','Tulipa']\n\nfor category in CATEGORIES :\n    path = os.path.join(DATADIR, category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_UNCHANGED)\n\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES :\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try :\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_UNCHANGED)\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                training_data.append([new_array, class_num])\n            except Exception as e:\n                pass\n\ncreate_training_data()\n\nrandom.shuffle(training_data)\n\nX = [] \ny = []\n\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny = np.asarray(y)\npickle_out = open(\"X.pickle\", \"wb\")\npickle.dump(X, pickle_out)\npickle_out.close()\n\npickle_out = open(\"y.pickle\", \"wb\")\npickle.dump(y, pickle_out)\npickle_out.close()\n\npickle_in = open(\"X.pickle\", \"rb\")\nX = pickle.load(pickle_in)\n\nX = X/255.0\n\ndata_augmentation = tf.keras.Sequential([\n  layers.RandomFlip(\"horizontal_and_vertical\"), #Randomly flip each image horizontally and vertically.\n  layers.RandomRotation(0.2),\n])\n\nmodel = models.Sequential()\ndata_augmentation\n# 3 convolutional layers\nmodel.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n# 2 hidden layers\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(Dense(128))\nmodel.add(Activation(\"relu\"))\n\n#Output layer for 5 classes\nmodel.add(Dense(5))\nmodel.add(Activation(\"softmax\"))\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n\t\t\t\toptimizer=\"adam\",\n\t\t\t\tmetrics=[\"acc\"])\n\n# Training the model, with 40 iterations\n# validation_split corresponds to the percentage of images used for the validation phase compared to all the images\nhistory = model.fit(X, y, batch_size=32, epochs=30, validation_split=0.1)\n\n# Saving the model\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file :\n\tjson_file.write(model_json)\n\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n\nmodel.save('CNN.model')\n\n# Printing a graph showing the accuracy changes during the training phase\nprint(history.history.keys())\nplt.figure(1)\nplt.plot(history.history[\"acc\"])\nplt.plot(history.history[\"val_acc\"])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}